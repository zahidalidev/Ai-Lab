{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-f406cc44edc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_version_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data  # input\n",
    "y = iris.target  # output\n",
    "\n",
    "dataset = pd.DataFrame(X, columns=iris.feature_names)\n",
    "dataset = pd.concat([dataset, pd.Series(y)], axis=1)\n",
    "\n",
    "dataset.rename(columns={0: 'class'}, inplace=True)\n",
    "\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.1)  # spliting dataset\n",
    "\n",
    "X_train = pd.DataFrame(X_train).astype(float).values.tolist()\n",
    "X_test = X_test.astype(float).values.tolist()\n",
    "\n",
    "\n",
    "# euclidean distance to find the distance between two points. d(p, q) = sqrt((p1-q1)**2)\n",
    "def euclidean_distance(p1, q1):\n",
    "    p1, q1 = np.array(p1), np.array(q1)\n",
    "    distance = 0\n",
    "    for i in range(len(p1)-1):\n",
    "        distance += (p1[i] - q1[i]) ** 2  # adding into distance\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "\n",
    "def knn(X_train, pred, k=1):\n",
    "    distances = []\n",
    "    k_neighbors = []  # storing neighbors\n",
    "    count_resposes = {}\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        eucl_dist = euclidean_distance(X_train[i][:-1], pred) # getting distance to append in distances\n",
    "        distances.append((X_train[i], eucl_dist))\n",
    "\n",
    "    distances.sort(key=lambda x: x[1]) # sorting by distance\n",
    "\n",
    "    for i in range(k):\n",
    "        k_neighbors.append(distances[i][0])  # appending k nearest neighbors that have smallest distance \n",
    "\n",
    "    for i in range(len(k_neighbors)):\n",
    "        response = k_neighbors[i][-1]  # target \n",
    "        \n",
    "        if response in count_resposes: # if exist in count_response then increment by 1\n",
    "            count_resposes[response] += 1\n",
    "        else: # if not exist in count_response then set to 1\n",
    "            count_resposes[response] = 1\n",
    "\n",
    "    count_resposes_sorted = sorted(count_resposes.items(), key=lambda x: x[1], reverse=True) # sorting in desceing order by value\n",
    "\n",
    "    # 1st one has mejority thats why returning that\n",
    "    return count_resposes_sorted[0][0]\n",
    "\n",
    "\n",
    "predictions = []\n",
    "y_test = []\n",
    "\n",
    "for row in X_test:\n",
    "    pred = row[:-1]\n",
    "    prediction = knn(X_train, pred, 6)\n",
    "    predictions.append(prediction)\n",
    "    y_test.append(row[4])\n",
    "\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print('Predictions:', predictions)\n",
    "print('accuracy:', score)\n",
    "\n",
    "\n",
    "########################################## Accuracy, Training and Validation graphs ######################################\n",
    "# accuracy graph\n",
    "predictions2 = []\n",
    "y_test2 = []\n",
    "k = 1\n",
    "accuracy = []\n",
    "for row in X_test:\n",
    "    pred = row[:-1]\n",
    "    prediction = knn(X_train, pred, k)\n",
    "    predictions2.append(prediction)\n",
    "    y_test2.append(row[4])\n",
    "    score = accuracy_score(y_test2, predictions2)\n",
    "    accuracy.append(score)\n",
    "    k = k + 1\n",
    "\n",
    "plt.plot(range(1, 16), accuracy)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Testing Accuracy Graph')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sizes, training_scores, testing_scores = learning_curve(KNeighborsClassifier(\n",
    "), X, y, cv=None, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 100))\n",
    "\n",
    "# for training error graph\n",
    "\n",
    "# Mean and Standard Deviation of training scores\n",
    "m_training = np.mean(training_scores, axis=1)\n",
    "SD_training = np.std(training_scores, axis=1)\n",
    "plt.plot(sizes, m_training, color=\"b\", label=\"Training score\")\n",
    "\n",
    "plt.title(\"Training error graph\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\n",
    "    \"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# for validation error graph\n",
    "# Mean and Standard Deviation of testing scores\n",
    "m_testing = np.mean(testing_scores, axis=1)\n",
    "SD_testing = np.std(testing_scores, axis=1)\n",
    "plt.plot(sizes, m_testing, color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "plt.title(\"Validation error graph\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\n",
    "    \"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
